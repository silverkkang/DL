# 퍼셉트론(Perceptron)

- 우리 몸의 신경계가 뉴런으로 구성되듯 인공 신경망을 이루는 가장 작은 단위를 퍼셉트론(perceptron)이라고 함
- 뉴런은 ‘수상돌기 → 신경세포체/축삭 → 다음 뉴런의 수상돌기’라는 과정을 거쳐 신호를 전달함. 퍼셉트론도 이와 비슷한 구조를 가짐
- **가장 간단한 인공 신경망 구조** : 1957년에 프랑크 로젠블라트가 제안
- 헤비사이드 계단 함수를 통한 출력이 특징 (범위 : -1, 0, 1)


### Wx+b

1. 퍼셉트론이 결정을 내리기 위해 **모든 정보를 종합해 '총점'을 내는 계산식**
2. 이 총점이 0이 되는 지점(Wx+b=0)은 데이터를 두 그룹으로 나누는 분류 '경계선'(직선 또는 평면)을 의미


## 활성화 함수(Activation Function)

- 자기가 받은 신호를 잘 살려서 내보내주는 역할
    - 가중합(가중치*입력값 들의 합, Wx)이 계산되고 나면 값이 너무 크거나 작을 수 있음. 이 때 활성화 함수를 통해서 이 1 또는 -1에서 1사이의 값 등으로 변환함
    - 비선형성을 가진 활성화 함수를 통해서 Wx+b를 휘게 만듦
- 계단함수, 시그모이드, ReLU, ReLU의 변형, 소프트맥스 함수 등이 있음









# MLP(Multi Layer Perceptron)

- **여러 층의 퍼셉트론이 결합된 인공신경망** 구조
- **원은 노드(node)**라고 하며, 전체는 크게 세 부분
입력층(Input Layer), 은닉층(Hidden Layers), 출력층(Output Layer)으로 나누어진다.
- **Fully-Connected Layer** : 완전 연결 계층으로 구성
각각의 노드는 인접한 층이 보유한 모든 노드들과 연결되어 있음
- **Feed-Forward Network** : 순전파 네트워크의 한 종류임
입력층부터 출력층까지 순서대로 변수들을 계산하여 정보를 전달하고 최종 결과를
산출하는 네트워크


## 입력층(Input Layer)

- 데이터셋이 입력되는 층
- 데이터셋의 특성(feature) 개수에 맞춰 입력층의 노드 수가 결정됨
- 어떤 계산 없이 입력값의 전달만 수행 -> 신경망 층수(깊이, depth)에 포함되지 않음

## 은닉층(Hidden Layers)

- 입력층에서 들어온 값이 가중치-편향 연산 및 활성화 함수를 거쳐가는 층
- 일반적으로 입력층과 출력층 사이에 있는 층임
- 사용자가 계산 결과를 볼 수 없음 = 은닉(hidden)층
- 입력 데이터셋의 특성 수와 관계없이 노드 수 구성 가능
    
    ※ 딥 러닝 : 2개 이상의 은닉층을 가진 신경망

## 출력층(Output Layer)

- 은닉층의 연산을 마친 값이 출력되는 층
- 해결할 문제에 따라 출력층의 노드 수가 결정됨

## 순전파 (Forward propagation)

 **순전파는 '입력'에서 '출력(예측값)'까지 데이터가 한 방향으로 흘러가며 계산되는 과정**

- 입력층의 노드들은 입력 데이터(특징 벡터)를 받아 다음 은닉층으로 전달
- 은닉층은 모델의 형태에 따라 다음 은닉층 또는 출력층으로 특징 벡터의 연산 결과를 전달
- 은닉층과 출력층의 각 노드는 가중합 연산 이후에 활성화 함수를 적용하는 두 가지 연산을 단계적으로 수행
